{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccdd6d5",
   "metadata": {},
   "source": [
    "### train C-VQ-VAE model (execute train_c_vq_vae_model.py)\n",
    "\n",
    "- we set max_epoch as 5 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efcf2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working in directory: /mnt/e/SC-SatCom/ver 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:08:07.714409: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 11:08:07.736891: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 11:08:08.139169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 11:08:08.837486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.856073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.856369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.858335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.858599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.858875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.990595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.990886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.990905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 11:08:08.991110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:08:08.991142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_name='cifar10', config='config/cifar10/model_config.yaml', img_size=32, max_epoch=5, num_modulations=5, num_embeddings=512, save_interval=10, commitment_cost=0.5, decay=0.99, init_lr=0.001, batch_size=128, embedding_dim=32, n_res_block=2, num_samples=4, save_model_dir='./vqvae_model/cifar10', save_img_dir='./vqvae_images/cifar10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Training:   0%|          | 0/351 [00:00<?, ?it/s]2025-09-23 11:08:14.652153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 11:08:14.729761: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:08:15.359700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 11:08:17.111602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f901a2ad100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 11:08:17.111637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-09-23 11:08:17.114130: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 11:08:17.174470: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:08:17.214037: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Epoch 1/5 - Training:   3%|▎         | 9/351 [00:16<03:17,  1.73it/s]WARNING:tensorflow:5 out of the last 10 calls to <function train_step at 0x7f91f61cf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function train_step at 0x7f91f61cf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/5 - Training: 100%|██████████| 351/351 [00:55<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.2569, Val Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Training:   3%|▎         | 9/351 [00:06<01:23,  4.08it/s]WARNING:tensorflow:5 out of the last 352 calls to <function train_step at 0x7f91f61cf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 352 calls to <function train_step at 0x7f91f61cf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 2/5 - Training: 100%|██████████| 351/351 [00:46<00:00,  7.51it/s]\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function val_step at 0x7f91f61cf130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function val_step at 0x7f91f61cf130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function val_step at 0x7f91f61cf130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function val_step at 0x7f91f61cf130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.6615, Val Loss: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Training: 100%|██████████| 351/351 [00:46<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.5524, Val Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Training: 100%|██████████| 351/351 [00:46<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.5036, Val Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Training: 100%|██████████| 351/351 [00:46<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.4809, Val Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:12:29.515931: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel awgn, Modulation 0, Mean PSNR: 19.88 dB\n",
      "Channel awgn, Modulation 0, Mean PSNR: 20.87 dB\n",
      "Channel awgn, Modulation 0, Mean PSNR: 21.55 dB\n",
      "Channel awgn, Modulation 0, Mean PSNR: 22.21 dB\n",
      "Channel awgn, Modulation 0, Mean PSNR: 22.80 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 21.80 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 22.53 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 22.91 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 23.33 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 23.53 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 23.61 dB\n",
      "Channel awgn, Modulation 1, Mean PSNR: 23.67 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.05 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.26 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.38 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.54 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.58 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.61 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.65 dB\n",
      "Channel awgn, Modulation 2, Mean PSNR: 21.65 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 22.80 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 22.96 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 23.06 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 23.12 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 23.17 dB\n",
      "Channel awgn, Modulation 3, Mean PSNR: 23.17 dB\n",
      "Channel awgn, Modulation 4, Mean PSNR: 23.19 dB\n",
      "Channel awgn, Modulation 4, Mean PSNR: 23.32 dB\n",
      "Channel awgn, Modulation 4, Mean PSNR: 23.40 dB\n",
      "Channel awgn, Modulation 4, Mean PSNR: 23.45 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:12:31.976635: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel rician, Modulation 0, Mean PSNR: 20.26 dB\n",
      "Channel rician, Modulation 0, Mean PSNR: 20.84 dB\n",
      "Channel rician, Modulation 0, Mean PSNR: 21.19 dB\n",
      "Channel rician, Modulation 0, Mean PSNR: 21.63 dB\n",
      "Channel rician, Modulation 0, Mean PSNR: 21.85 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 21.35 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 21.68 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 22.13 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 22.36 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 22.55 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 22.86 dB\n",
      "Channel rician, Modulation 1, Mean PSNR: 22.99 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 20.79 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 20.98 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.11 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.19 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.35 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.32 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.44 dB\n",
      "Channel rician, Modulation 2, Mean PSNR: 21.48 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.53 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.64 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.77 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.84 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.92 dB\n",
      "Channel rician, Modulation 3, Mean PSNR: 22.98 dB\n",
      "Channel rician, Modulation 4, Mean PSNR: 23.14 dB\n",
      "Channel rician, Modulation 4, Mean PSNR: 23.22 dB\n",
      "Channel rician, Modulation 4, Mean PSNR: 23.25 dB\n",
      "Channel rician, Modulation 4, Mean PSNR: 23.29 dB\n",
      "Channel rayleigh, Modulation 0, Mean PSNR: 17.59 dB\n",
      "Channel rayleigh, Modulation 0, Mean PSNR: 18.31 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:12:33.853693: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel rayleigh, Modulation 0, Mean PSNR: 18.84 dB\n",
      "Channel rayleigh, Modulation 0, Mean PSNR: 19.41 dB\n",
      "Channel rayleigh, Modulation 0, Mean PSNR: 19.85 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 19.05 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 19.58 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 20.15 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 20.65 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 21.10 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 21.52 dB\n",
      "Channel rayleigh, Modulation 1, Mean PSNR: 21.85 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 19.85 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 20.09 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 20.32 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 20.51 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 20.70 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 20.89 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 21.01 dB\n",
      "Channel rayleigh, Modulation 2, Mean PSNR: 21.09 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 21.69 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 21.83 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 22.06 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 22.26 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 22.43 dB\n",
      "Channel rayleigh, Modulation 3, Mean PSNR: 22.59 dB\n",
      "Channel rayleigh, Modulation 4, Mean PSNR: 22.57 dB\n",
      "Channel rayleigh, Modulation 4, Mean PSNR: 22.72 dB\n",
      "Channel rayleigh, Modulation 4, Mean PSNR: 22.84 dB\n",
      "Channel rayleigh, Modulation 4, Mean PSNR: 23.01 dB\n",
      "C-VQ-VAE model training completed!\n"
     ]
    }
   ],
   "source": [
    "import subprocess, os, sys\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "print(f\"Working in directory: {project_dir}\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-u', 'train_c_vq_vae_model.py', '--dataset_name', 'cifar10'], \n",
    "    cwd=project_dir,\n",
    "    check=True\n",
    ") \n",
    "\n",
    "print(\"C-VQ-VAE model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2bff3",
   "metadata": {},
   "source": [
    "### save psnr and symbol data (execute save_psnr_data.py and save_symbol_data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0559681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PSNR data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:05:24.874066: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 11:05:24.896909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 11:05:25.286494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 11:05:26.274407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.292326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.292650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.294598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.294834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.295046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.416160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.416454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.416473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 11:05:26.416692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:26.416721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_name='cifar10', config='config/cifar10/model_config.yaml', img_size=32, num_modulations=5, num_embeddings=512, commitment_cost=0.5, decay=0.99, batch_size=128, embedding_dim=32, n_res_block=2, vqvae_model_dir='./vqvae_model/cifar10', save_dir='./doppler_data/cifar10')\n",
      "[SKIP] Both train/val tfrecords already exist in ./doppler_data/cifar10.\n",
      "\n",
      "Saving Symbol data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:05:27.139901: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 11:05:27.162136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 11:05:27.542205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 11:05:28.533175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.549007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.549343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.550863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.551150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.551394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.666605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.666881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.666900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 11:05:28.667167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:05:28.667204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_name='cifar10', config='config/cifar10/model_config.yaml', img_size=32, num_modulations=5, num_embeddings=512, commitment_cost=0.5, decay=0.99, batch_size=32, save_rl_model_dir='./rl_model/cifar10', embedding_dim=32, n_res_block=2, vqvae_model_dir='./vqvae_model/cifar10', save_dir='./doppler_data/cifar10')\n",
      "[SKIP] Both train/val symbol tfrecords already exist in ./doppler_data/cifar10\n",
      "PSNR and Symbol data saving completed!\n"
     ]
    }
   ],
   "source": [
    "# Save PSNR and Symbol Data\n",
    "import subprocess\n",
    "import os, sys\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "print(\"Saving PSNR data...\")\n",
    "try:\n",
    "    result_psnr = subprocess.run(\n",
    "        [sys.executable, \"-u\", \"save_psnr_data.py\",\n",
    "         \"--dataset_name\", \"cifar10\"],\n",
    "        cwd=project_dir,\n",
    "        check=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error running save_psnr_data.py: {e}\")\n",
    "\n",
    "print(\"\\nSaving Symbol data...\")\n",
    "try:\n",
    "    result_symbol = subprocess.run(\n",
    "        [sys.executable, \"-u\", \"save_symbol_data.py\",\n",
    "         \"--dataset_name\", \"cifar10\"],\n",
    "        cwd=project_dir,\n",
    "        check=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error running save_symbol_data.py: {e}\")\n",
    "\n",
    "print(\"PSNR and Symbol data saving completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8bc17",
   "metadata": {},
   "source": [
    "### train ppo agent (execute train_tx_agent_ppo.py)\n",
    "- we set max_epoch as 5 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63750d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO Agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:13:01.679177: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 11:13:01.701123: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 11:13:02.100726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 11:13:03.090229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.108814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.109111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.110954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.111155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.111392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.254824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.255241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.255268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 11:13:03.256014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:13:03.256060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_name='cifar10', config='config/cifar10/model_config.yaml', img_size=32, max_epoch=5, num_modulations=5, num_embeddings=512, commitment_cost=0.5, decay=0.99, actor_lr=0.0001, critic_lr=0.0005, batch_size=128, embedding_dim=32, n_res_block=2, save_model_dir='./rl_model/cifar10', save_img_dir='./rl_images/cifar10', vqvae_model_dir='./vqvae_model/cifar10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:13:04.029757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 11:13:04.102678: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:13:04.258559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_train/cifar10/doppler_NTN-TDL-A.tfrecord already exists, skipping.\n",
      "split_val/cifar10/doppler_NTN-TDL-A.tfrecord already exists, skipping.\n",
      "split_train/cifar10/doppler_NTN-TDL-B.tfrecord already exists, skipping.\n",
      "split_val/cifar10/doppler_NTN-TDL-B.tfrecord already exists, skipping.\n",
      "split_train/cifar10/doppler_NTN-TDL-C.tfrecord already exists, skipping.\n",
      "split_val/cifar10/doppler_NTN-TDL-C.tfrecord already exists, skipping.\n",
      "split_train/cifar10/doppler_NTN-TDL-D.tfrecord already exists, skipping.\n",
      "split_val/cifar10/doppler_NTN-TDL-D.tfrecord already exists, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:13:09.372431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0c35f3fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 11:13:09.372463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-09-23 11:13:09.375076: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 11:13:09.434648: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:13:09.466161: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Reward: 0.5396, Train PSNR: 23.705, Avg Val Reward: 0.6343, Avg Val PSNR: 26.515\n",
      "  ▶ New best avg val reward; model saved.\n",
      "Epoch 2 | Train Reward: 0.6488, Train PSNR: 26.878, Avg Val Reward: 0.6647, Avg Val PSNR: 27.187\n",
      "  ▶ New best avg val reward; model saved.\n",
      "Epoch 3 | Train Reward: 0.6673, Train PSNR: 27.224, Avg Val Reward: 0.6706, Avg Val PSNR: 27.252\n",
      "  ▶ New best avg val reward; model saved.\n",
      "Epoch 4 | Train Reward: 0.6702, Train PSNR: 27.293, Avg Val Reward: 0.6719, Avg Val PSNR: 27.267\n",
      "  ▶ New best avg val reward; model saved.\n",
      "Epoch 5 | Train Reward: 0.6648, Train PSNR: 27.112, Avg Val Reward: 0.6682, Avg Val PSNR: 27.200\n",
      "PPO Agent training completed!\n",
      "RL model saved successfully in: ./rl_model/cifar10\n",
      "Files in RL model directory:\n",
      "  - tx_actor.h5\n",
      "  - tx_critic.h5\n"
     ]
    }
   ],
   "source": [
    "# Train PPO Agent\n",
    "import subprocess\n",
    "import os, sys\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "print(\"Training PPO Agent...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-u\", \"train_tx_agent_ppo.py\", \"--dataset_name\", \"cifar10\"], \n",
    "        cwd=project_dir,\n",
    "        check=True\n",
    "    )\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"PPO Training failed.\")\n",
    "    print(\"Return code:\", e.returncode)\n",
    "except Exception as e:\n",
    "    print(f\"Error running train_tx_agent_ppo.py: {e}\")\n",
    "else:\n",
    "    print(\"PPO Agent training completed!\")\n",
    "\n",
    "rl_model_path = \"./rl_model/cifar10\"\n",
    "if os.path.exists(rl_model_path):\n",
    "    print(f\"RL model saved successfully in: {rl_model_path}\")\n",
    "    print(\"Files in RL model directory:\")\n",
    "    for file in os.listdir(rl_model_path):\n",
    "        print(f\"  - {file}\")\n",
    "else:\n",
    "    print(\"Warning: RL model directory not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fe0e1",
   "metadata": {},
   "source": [
    "### train_post_model (execute train_post_model.py)\n",
    "- we set max_epoch as 1 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc33657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Post Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:16:43.928290: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 11:16:43.962843: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 11:16:44.407486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 11:16:45.321254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.340147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.340482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.342407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.342647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.342868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.473063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.473514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.473538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 11:16:45.473906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 11:16:45.473948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_name='cifar10', config='config/cifar10/model_config.yaml', img_size=32, learning_rate=0.0001, max_epoch=1, num_modulations=5, num_embeddings=512, commitment_cost=0.5, decay=0.99, batch_size=32, embedding_dim=32, n_res_block=2, vqvae_model_dir='./vqvae_model/cifar10', post_model_dir='./post_model/cifar10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 11:16:46.324732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 11:16:46.390262: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:16:46.546732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Training:   0%|          | 0/1406 [00:00<?, ?it/s]2025-09-23 11:16:48.626142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1371217ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 11:16:48.626169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-09-23 11:16:48.628828: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 11:16:48.690220: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-09-23 11:16:48.720516: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Training: 100%|██████████| 1406/1406 [02:44<00:00,  8.55it/s]\n",
      "Training:   0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.07614648342132568, LMMSE PSNR: 21.92250633239746, Post LMMSE PSNR: 20.811664581298828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 156/156 [00:09<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.03142847865819931, LMMSE PSNR: 27.75175666809082, Post LMMSE PSNR: 27.368900299072266\n",
      "Post Model training completed!\n",
      "Post model saved successfully in: ./post_model/cifar10\n",
      "Files in Post model directory:\n",
      "  - post_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Train Post Model\n",
    "import subprocess\n",
    "import os, sys\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "print(\"Training Post Model...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-u\", \"train_post_model.py\",\n",
    "         \"--dataset_name\", \"cifar10\"], \n",
    "        cwd=project_dir,\n",
    "        check=True  \n",
    "    )\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Post Model Training failed with return code:\", e.returncode)\n",
    "except Exception as e:\n",
    "    print(f\"Error running train_post_model.py: {e}\")\n",
    "else:\n",
    "    print(\"Post Model training completed!\")\n",
    "\n",
    "# Check if post model was saved successfully\n",
    "post_model_path = \"./post_model/cifar10\"\n",
    "if os.path.exists(post_model_path):\n",
    "    print(f\"Post model saved successfully in: {post_model_path}\")\n",
    "    print(\"Files in Post model directory:\")\n",
    "    for file in os.listdir(post_model_path):\n",
    "        print(f\"  - {file}\")\n",
    "else:\n",
    "    print(\"Warning: Post model directory not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b40e70",
   "metadata": {},
   "source": [
    "### Evaluate Performance of Model (execute app_tk.py for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daeeca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch GUI Application (app_tk.py)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance and Launch Visualization GUI\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "print(\"Launch GUI Application (app_tk.py)\")\n",
    "\n",
    "try:\n",
    "    gui_proc = subprocess.Popen(\n",
    "        [sys.executable, \"-u\", \"app_tk.py\"],\n",
    "        cwd=project_dir,\n",
    "        stdout=None,         \n",
    "        stderr=None\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error launching GUI: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_comm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
